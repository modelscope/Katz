[SUYI] Using EulerDiscreteScheduler
[SUYI] In unet_2d_condition.py
[SUYI] USE_PEFT_BACKEND=True in loaders/lora.py
Args Namespace(skipped_steps=20, enable_hit_ratio=False, serve_mode='standard', lora_mode='full', load_lora_mode='default', num_controlnets=1, num_loras=1)
Nirvana config {'K': 20, 'hit_ratio': 0.2}
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] load_state_dict: safetensors.torch.load_file(/home/slida/.cache/huggingface/hub/models--diffusers--controlnet-depth-sdxl-1.0/snapshots/17bb97973f29801224cd66f192c5ffacf82648b4/diffusion_pytorch_model.fp16.safetensors)
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] load_state_dict: safetensors.torch.load_file(/home/slida/.cache/huggingface/hub/models--madebyollin--sdxl-vae-fp16-fix/snapshots/207b116dae70ace3637169f1ddd2434b91b3a8cd/diffusion_pytorch_model.safetensors)
[SUYI] Using customized pipeline_stable_diffusion_xl
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Loading pipeline components...:  14%|█▍        | 1/7 [00:00<00:00,  9.72it/s]Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00,  5.51it/s]Loading pipeline components...:  57%|█████▋    | 4/7 [00:13<00:12,  4.16s/it]Loading pipeline components...:  71%|███████▏  | 5/7 [00:13<00:05,  2.93s/it]Loading pipeline components...:  86%|████████▌ | 6/7 [00:14<00:02,  2.21s/it]Loading pipeline components...: 100%|██████████| 7/7 [00:14<00:00,  2.02s/it]
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] norm_num_groups: 32
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_cuda_graph: False
[LINGYUN] load_state_dict: safetensors.torch.load_file(/home/slida/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-base-1.0/snapshots/462165984030d82259a11f4367a4eed129e94a7b/unet/diffusion_pytorch_model.fp16.safetensors)
0 papercut -subject/scene-a long wooden bench in front of a brick wall, 4k, clean background
[SUYI] load_file_time=0.543
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.304
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.46
[SUYI] load_lora_into_unet_time=2.472
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  3%|▎         | 1/30 [00:00<00:06,  4.15it/s] 10%|█         | 3/30 [00:00<00:03,  8.73it/s] 17%|█▋        | 5/30 [00:00<00:02, 10.21it/s] 23%|██▎       | 7/30 [00:00<00:02, 10.95it/s] 30%|███       | 9/30 [00:00<00:01, 11.37it/s] 37%|███▋      | 11/30 [00:01<00:01, 11.65it/s] 43%|████▎     | 13/30 [00:01<00:01, 11.82it/s] 50%|█████     | 15/30 [00:01<00:01, 11.94it/s] 57%|█████▋    | 17/30 [00:01<00:01, 12.01it/s] 63%|██████▎   | 19/30 [00:01<00:00, 12.07it/s] 70%|███████   | 21/30 [00:01<00:00, 12.10it/s] 77%|███████▋  | 23/30 [00:02<00:00, 12.13it/s] 83%|████████▎ | 25/30 [00:02<00:00, 12.14it/s] 90%|█████████ | 27/30 [00:02<00:00, 12.16it/s] 97%|█████████▋| 29/30 [00:02<00:00, 12.16it/s]100%|██████████| 30/30 [00:02<00:00, 11.54it/s]
Load LoRA latency: 3.47
End2End inference latency: 6.59
==============================
1 papercut -subject/scene-a cat looking out of a window, 4k, clean background
[SUYI] load_file_time=0.479
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.871
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.03
[SUYI] load_lora_into_unet_time=2.038
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.27it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.95it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.26it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.24it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.20it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.20it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.20it/s]100%|██████████| 30/30 [00:02<00:00, 12.20it/s]100%|██████████| 30/30 [00:02<00:00, 12.31it/s]
Load LoRA latency: 2.63
End2End inference latency: 5.30
==============================
2 papercut -subject/scene-A helicopter flies over Yosemite., 4k, clean background
[SUYI] load_file_time=0.481
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.862
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.02
[SUYI] load_lora_into_unet_time=2.029
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.27it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.94it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.26it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.24it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.20it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.20it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.20it/s]100%|██████████| 30/30 [00:02<00:00, 12.20it/s]100%|██████████| 30/30 [00:02<00:00, 12.31it/s]
Load LoRA latency: 2.62
End2End inference latency: 5.30
==============================
3 papercut -subject/scene-a handsaw on a table, 4k, clean background
[SUYI] load_file_time=0.514
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.853
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.12
[SUYI] load_lora_into_unet_time=2.124
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.25it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.94it/s] 20%|██        | 6/30 [00:00<00:01, 12.58it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.42it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.75
End2End inference latency: 5.43
==============================
4 papercut -subject/scene-A smiling sloth wearing a bowtie and holding a quarterstaff and a big book. A shiny VW van parked on grass., 4k, clean background
[SUYI] load_file_time=0.477
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.784
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.059
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.25it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.60it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.44it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.35it/s] 40%|████      | 12/30 [00:00<00:01, 12.30it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.26it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.24it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.21it/s] 80%|████████  | 24/30 [00:01<00:00, 12.20it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.20it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.20it/s]100%|██████████| 30/30 [00:02<00:00, 12.20it/s]100%|██████████| 30/30 [00:02<00:00, 12.31it/s]
Load LoRA latency: 2.65
End2End inference latency: 5.32
==============================
5 papercut -subject/scene-a large present with a red ribbon, 4k, clean background
[SUYI] load_file_time=0.477
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.803
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.06
[SUYI] load_lora_into_unet_time=2.078
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.27it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.60it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.26it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.24it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.20it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.66
End2End inference latency: 5.34
==============================
6 papercut -subject/scene-a cat reading a book, 4k, clean background
[SUYI] load_file_time=0.528
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.791
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.063
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.26it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.23it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.27it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.25it/s] 60%|██████    | 18/30 [00:01<00:00, 12.23it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.20it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.70
End2End inference latency: 5.38
==============================
7 papercut -subject/scene-the Beatles crossing Abbey road, 4k, clean background
[SUYI] load_file_time=0.649
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.800
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.06
[SUYI] load_lora_into_unet_time=2.072
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.26it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.83
End2End inference latency: 5.51
==============================
8 papercut -subject/scene-a woman singing into a microphone, 4k, clean background
[SUYI] load_file_time=0.468
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.789
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.056
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.28it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.60it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.29it/s]
Load LoRA latency: 2.63
End2End inference latency: 5.31
==============================
9 papercut -subject/scene-a white robot passing a soccer ball to a red robot, 4k, clean background
[SUYI] load_file_time=0.485
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.787
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.061
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.24it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.95it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.66
End2End inference latency: 5.34
==============================
10 papercut -subject/scene-a plant growing on the side of a brick wall, 4k, clean background
[SUYI] load_file_time=0.497
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.793
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.06
[SUYI] load_lora_into_unet_time=2.065
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.25it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.95it/s] 20%|██        | 6/30 [00:00<00:01, 12.58it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.42it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.67
End2End inference latency: 5.35
==============================
11 papercut -subject/scene-snow covering the Great Pyramid, 4k, clean background
[SUYI] load_file_time=0.472
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.778
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.053
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.25it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.95it/s] 20%|██        | 6/30 [00:00<00:01, 12.58it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.42it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.33it/s] 40%|████      | 12/30 [00:00<00:01, 12.28it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.63
End2End inference latency: 5.31
==============================
12 papercut -subject/scene-a photograph of a house on a mountain, 4k, clean background
[SUYI] load_file_time=0.462
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.798
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.057
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.27it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.95it/s] 20%|██        | 6/30 [00:00<00:01, 12.58it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.42it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.33it/s] 40%|████      | 12/30 [00:00<00:01, 12.28it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.62
End2End inference latency: 5.30
==============================
13 papercut -subject/scene-an owl standing on a wire, 4k, clean background
[SUYI] load_file_time=0.514
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.789
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.057
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.31it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.97it/s] 20%|██        | 6/30 [00:00<00:01, 12.60it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.28it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.68
End2End inference latency: 5.36
==============================
14 papercut -subject/scene-a kids' book cover with an illustration of white dog driving a red pickup truck, 4k, clean background
[SUYI] load_file_time=0.474
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.788
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.061
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.29it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.60it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.64
End2End inference latency: 5.32
==============================
15 papercut -subject/scene-a subway train coming out of a tunnel, 4k, clean background
[SUYI] load_file_time=0.470
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.767
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.049
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.26it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.63
End2End inference latency: 5.31
==============================
16 papercut -subject/scene-a stone path leading away from a fountain, 4k, clean background
[SUYI] load_file_time=0.507
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.778
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.061
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.24it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.94it/s] 20%|██        | 6/30 [00:00<00:01, 12.58it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.41it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.32it/s] 40%|████      | 12/30 [00:00<00:01, 12.27it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.24it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.22it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.29it/s]
Load LoRA latency: 2.68
End2End inference latency: 5.36
==============================
17 papercut -subject/scene-an antique car by a beach, 4k, clean background
[SUYI] load_file_time=0.542
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.785
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.052
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.25it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.28it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.18it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.70
End2End inference latency: 5.38
==============================
18 papercut -subject/scene-black hi-top sneakers with the Nike swoosh, 4k, clean background
[SUYI] load_file_time=0.477
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.788
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.054
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.24it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.20it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.64
End2End inference latency: 5.32
==============================
19 papercut -subject/scene-a witch riding a broom, 4k, clean background
[SUYI] load_file_time=0.474
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.787
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.058
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.24it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.95it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.64
End2End inference latency: 5.32
==============================
20 papercut -subject/scene-a sword in a stone, 4k, clean background
[SUYI] load_file_time=0.472
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.780
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.048
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.26it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.20it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.20it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.62
End2End inference latency: 5.30
==============================
21 papercut -subject/scene-cash on a wooden table, 4k, clean background
[SUYI] load_file_time=0.475
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.752
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.02
[SUYI] load_lora_into_unet_time=2.025
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.25it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.28it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.61
End2End inference latency: 5.28
==============================
22 papercut -subject/scene-the Millennium Wheel in a snow storm, 4k, clean background
[SUYI] load_file_time=0.474
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.772
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.03
[SUYI] load_lora_into_unet_time=2.041
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.25it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.94it/s] 20%|██        | 6/30 [00:00<00:01, 12.58it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.42it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.33it/s] 40%|████      | 12/30 [00:00<00:01, 12.28it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.63
End2End inference latency: 5.31
==============================
23 papercut -subject/scene-a knight holding a long sword, 4k, clean background
[SUYI] load_file_time=0.471
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.779
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.052
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.31it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.99it/s] 20%|██        | 6/30 [00:00<00:01, 12.61it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.44it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.35it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.31it/s]
Load LoRA latency: 2.63
End2End inference latency: 5.32
==============================
24 papercut -subject/scene-a smiling sloth, 4k, clean background
[SUYI] load_file_time=0.476
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.770
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.03
[SUYI] load_lora_into_unet_time=2.038
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.30it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.98it/s] 20%|██        | 6/30 [00:00<00:01, 12.60it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.44it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.35it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.26it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.22it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.21it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.31it/s]
Load LoRA latency: 2.62
End2End inference latency: 5.30
==============================
25 papercut -subject/scene-a bundle of blue and yellow flowers in a vase, 4k, clean background
[SUYI] load_file_time=0.890
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.788
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.054
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.27it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.97it/s] 20%|██        | 6/30 [00:00<00:01, 12.60it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.44it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.29it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.20it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.19it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.19it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 3.05
End2End inference latency: 5.73
==============================
26 papercut -subject/scene-a cat coming through a cat door, 4k, clean background
[SUYI] load_file_time=0.653
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.780
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.049
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.27it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.28it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.22it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.19it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.18it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.81
End2End inference latency: 5.49
==============================
27 papercut -subject/scene-a pickup truck going up a mountain switchback, 4k, clean background
[SUYI] load_file_time=0.499
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.781
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.07
[SUYI] load_lora_into_unet_time=2.083
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.24it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.94it/s] 20%|██        | 6/30 [00:00<00:01, 12.58it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.42it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.33it/s] 40%|████      | 12/30 [00:00<00:01, 12.28it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.22it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.19it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.19it/s] 80%|████████  | 24/30 [00:01<00:00, 12.18it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.18it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.29it/s]
Load LoRA latency: 2.69
End2End inference latency: 5.38
==============================
28 papercut -subject/scene-a street in Paris, 4k, clean background
[SUYI] load_file_time=0.516
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.781
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.049
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.27it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.96it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.43it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.34it/s] 40%|████      | 12/30 [00:00<00:01, 12.28it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.23it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.19it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.18it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.30it/s]
Load LoRA latency: 2.68
End2End inference latency: 5.36
==============================
29 papercut -subject/scene-a teddy bear on a skateboard, 4k, clean background
[SUYI] load_file_time=0.476
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.784
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.054
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:01, 14.24it/s] 13%|█▎        | 4/30 [00:00<00:02, 12.95it/s] 20%|██        | 6/30 [00:00<00:01, 12.59it/s] 27%|██▋       | 8/30 [00:00<00:01, 12.42it/s] 33%|███▎      | 10/30 [00:00<00:01, 12.33it/s] 40%|████      | 12/30 [00:00<00:01, 12.28it/s] 47%|████▋     | 14/30 [00:01<00:01, 12.25it/s] 53%|█████▎    | 16/30 [00:01<00:01, 12.22it/s] 60%|██████    | 18/30 [00:01<00:00, 12.21it/s] 67%|██████▋   | 20/30 [00:01<00:00, 12.20it/s] 73%|███████▎  | 22/30 [00:01<00:00, 12.19it/s] 80%|████████  | 24/30 [00:01<00:00, 12.19it/s] 87%|████████▋ | 26/30 [00:02<00:00, 12.18it/s] 93%|█████████▎| 28/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.18it/s]100%|██████████| 30/30 [00:02<00:00, 12.29it/s]
Load LoRA latency: 2.64
End2End inference latency: 5.32
==============================
