[SUYI] Using EulerDiscreteScheduler
[SUYI] In unet_2d_condition.py
[SUYI] USE_PEFT_BACKEND=True in loaders/lora.py
Args Namespace(serve_mode='standard', lora_mode='full', load_lora_mode='default', num_controlnets=1, num_loras=1, skipped_steps=0)
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] load_state_dict: safetensors.torch.load_file(/home/slida/.cache/huggingface/hub/models--diffusers--controlnet-depth-sdxl-1.0/snapshots/17bb97973f29801224cd66f192c5ffacf82648b4/diffusion_pytorch_model.fp16.safetensors)
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] load_state_dict: safetensors.torch.load_file(/home/slida/.cache/huggingface/hub/models--madebyollin--sdxl-vae-fp16-fix/snapshots/207b116dae70ace3637169f1ddd2434b91b3a8cd/diffusion_pytorch_model.safetensors)
[SUYI] Using customized pipeline_stable_diffusion_xl
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Loading pipeline components...:  14%|█▍        | 1/7 [00:02<00:16,  2.69s/it]Loading pipeline components...:  29%|██▊       | 2/7 [00:02<00:06,  1.21s/it]Loading pipeline components...:  71%|███████▏  | 5/7 [00:15<00:06,  3.24s/it]Loading pipeline components...:  86%|████████▌ | 6/7 [00:15<00:02,  2.45s/it]Loading pipeline components...: 100%|██████████| 7/7 [00:15<00:00,  1.86s/it]Loading pipeline components...: 100%|██████████| 7/7 [00:15<00:00,  2.19s/it]
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] norm_num_groups: 32
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_cuda_graph: False
[LINGYUN] load_state_dict: safetensors.torch.load_file(/home/slida/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-base-1.0/snapshots/462165984030d82259a11f4367a4eed129e94a7b/unet/diffusion_pytorch_model.fp16.safetensors)
0 papercut -subject/scene-a long wooden bench in front of a brick wall, 4k, clean background
[SUYI] load_file_time=0.450
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.535
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.66
[SUYI] load_lora_into_unet_time=2.673
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:00<00:19,  2.49it/s]  6%|▌         | 3/50 [00:00<00:07,  6.41it/s] 10%|█         | 5/50 [00:00<00:05,  8.47it/s] 14%|█▍        | 7/50 [00:00<00:04,  9.71it/s] 18%|█▊        | 9/50 [00:01<00:03, 10.51it/s] 22%|██▏       | 11/50 [00:01<00:03, 11.04it/s] 26%|██▌       | 13/50 [00:01<00:03, 11.39it/s] 30%|███       | 15/50 [00:01<00:03, 11.63it/s] 34%|███▍      | 17/50 [00:01<00:02, 11.79it/s] 38%|███▊      | 19/50 [00:01<00:02, 11.91it/s] 42%|████▏     | 21/50 [00:02<00:02, 11.98it/s] 46%|████▌     | 23/50 [00:02<00:02, 12.03it/s] 50%|█████     | 25/50 [00:02<00:02, 12.07it/s] 54%|█████▍    | 27/50 [00:02<00:01, 12.09it/s] 58%|█████▊    | 29/50 [00:02<00:01, 12.11it/s] 62%|██████▏   | 31/50 [00:02<00:01, 12.12it/s] 66%|██████▌   | 33/50 [00:03<00:01, 12.13it/s] 70%|███████   | 35/50 [00:03<00:01, 12.14it/s] 74%|███████▍  | 37/50 [00:03<00:01, 12.14it/s] 78%|███████▊  | 39/50 [00:03<00:00, 12.15it/s] 82%|████████▏ | 41/50 [00:03<00:00, 12.15it/s] 86%|████████▌ | 43/50 [00:03<00:00, 12.16it/s] 90%|█████████ | 45/50 [00:03<00:00, 12.15it/s] 94%|█████████▍| 47/50 [00:04<00:00, 12.15it/s] 98%|█████████▊| 49/50 [00:04<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 11.34it/s]
Load LoRA latency: 3.54
End2End inference latency: 8.27
==============================
1 papercut -subject/scene-a cat looking out of a window, 4k, clean background
[SUYI] load_file_time=0.464
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 3.812
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 3.94
[SUYI] load_lora_into_unet_time=3.950
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.23it/s]  8%|▊         | 4/50 [00:00<00:03, 12.92it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.54it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.31it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.26it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.23it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.21it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.19it/s] 40%|████      | 20/50 [00:01<00:02, 12.18it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.17it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.16it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.16it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.15it/s] 60%|██████    | 30/50 [00:02<00:01, 12.15it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.15it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.15it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.15it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.15it/s] 80%|████████  | 40/50 [00:03<00:00, 12.15it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.15it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.15it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.15it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.22it/s]
Load LoRA latency: 4.51
End2End inference latency: 8.77
==============================
2 papercut -subject/scene-A helicopter flies over Yosemite., 4k, clean background
[SUYI] load_file_time=0.512
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.144
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.27
[SUYI] load_lora_into_unet_time=2.279
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.26it/s]  8%|▊         | 4/50 [00:00<00:03, 12.94it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.57it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.40it/s] 20%|██        | 10/50 [00:00<00:03, 12.32it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.26it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.17it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.17it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.16it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.16it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.15it/s] 60%|██████    | 30/50 [00:02<00:01, 12.15it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.16it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.15it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.15it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.15it/s] 80%|████████  | 40/50 [00:03<00:00, 12.15it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.15it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.15it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.15it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.22it/s]
Load LoRA latency: 2.89
End2End inference latency: 7.15
==============================
3 papercut -subject/scene-a handsaw on a table, 4k, clean background
[SUYI] load_file_time=0.513
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.131
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.34
[SUYI] load_lora_into_unet_time=2.346
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.23it/s]  8%|▊         | 4/50 [00:00<00:03, 12.94it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.57it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.40it/s] 20%|██        | 10/50 [00:00<00:03, 12.31it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.25it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.16it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.16it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.15it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.15it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.15it/s] 60%|██████    | 30/50 [00:02<00:01, 12.14it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.14it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.14it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.14it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.14it/s] 80%|████████  | 40/50 [00:03<00:00, 12.14it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.14it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.14it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.14it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.13it/s]100%|██████████| 50/50 [00:04<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.21it/s]
Load LoRA latency: 2.95
End2End inference latency: 7.21
==============================
4 papercut -subject/scene-A smiling sloth wearing a bowtie and holding a quarterstaff and a big book. A shiny VW van parked on grass., 4k, clean background
[SUYI] load_file_time=0.480
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.077
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.28
[SUYI] load_lora_into_unet_time=2.294
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.20it/s]  8%|▊         | 4/50 [00:00<00:03, 12.92it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.55it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.30it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.24it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.21it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.19it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.16it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.15it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.15it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.15it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.14it/s] 60%|██████    | 30/50 [00:02<00:01, 12.14it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.14it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.14it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.14it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.14it/s] 80%|████████  | 40/50 [00:03<00:00, 12.14it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.14it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.14it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.14it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.21it/s]
Load LoRA latency: 2.87
End2End inference latency: 7.13
==============================
5 papercut -subject/scene-a large present with a red ribbon, 4k, clean background
[SUYI] load_file_time=0.482
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.799
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.92
[SUYI] load_lora_into_unet_time=2.934
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.23it/s]  8%|▊         | 4/50 [00:00<00:03, 12.95it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.58it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.40it/s] 20%|██        | 10/50 [00:00<00:03, 12.29it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.26it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.19it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.17it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.16it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.15it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.15it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.15it/s] 60%|██████    | 30/50 [00:02<00:01, 12.15it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.14it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.14it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.14it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.14it/s] 80%|████████  | 40/50 [00:03<00:00, 12.14it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.14it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.14it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.14it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.21it/s]
Load LoRA latency: 3.51
End2End inference latency: 7.77
==============================
6 papercut -subject/scene-a cat reading a book, 4k, clean background
[SUYI] load_file_time=0.463
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.069
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.28
[SUYI] load_lora_into_unet_time=2.289
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.24it/s]  8%|▊         | 4/50 [00:00<00:03, 12.93it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.56it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.30it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.24it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.21it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.19it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.17it/s] 40%|████      | 20/50 [00:01<00:02, 12.16it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.15it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.15it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.15it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.14it/s] 60%|██████    | 30/50 [00:02<00:01, 12.14it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.14it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.14it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.14it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.14it/s] 80%|████████  | 40/50 [00:03<00:00, 12.14it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.14it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.13it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.14it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.13it/s]100%|██████████| 50/50 [00:04<00:00, 12.21it/s]
Load LoRA latency: 2.85
End2End inference latency: 7.11
==============================
7 papercut -subject/scene-the Beatles crossing Abbey road, 4k, clean background
[SUYI] load_file_time=0.460
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.084
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.29
[SUYI] load_lora_into_unet_time=2.303
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.22it/s]  8%|▊         | 4/50 [00:00<00:03, 12.94it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.57it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.40it/s] 20%|██        | 10/50 [00:00<00:03, 12.31it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.25it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.21it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.20it/s] 40%|████      | 20/50 [00:01<00:02, 12.19it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.18it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.18it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.18it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.17it/s] 60%|██████    | 30/50 [00:02<00:01, 12.17it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.17it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.17it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.17it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.17it/s] 80%|████████  | 40/50 [00:03<00:00, 12.17it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.17it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.16it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.17it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.17it/s]100%|██████████| 50/50 [00:04<00:00, 12.17it/s]100%|██████████| 50/50 [00:04<00:00, 12.24it/s]
Load LoRA latency: 2.86
End2End inference latency: 7.11
==============================
8 papercut -subject/scene-a woman singing into a microphone, 4k, clean background
[SUYI] load_file_time=0.491
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.109
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.32
[SUYI] load_lora_into_unet_time=2.327
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.20it/s]  8%|▊         | 4/50 [00:00<00:03, 12.91it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.54it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.31it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.26it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.23it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.21it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.19it/s] 40%|████      | 20/50 [00:01<00:02, 12.18it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.18it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.17it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.17it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.17it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.17it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.17it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.17it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.17it/s] 80%|████████  | 40/50 [00:03<00:00, 12.17it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.17it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.16it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.17it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.17it/s]100%|██████████| 50/50 [00:04<00:00, 12.17it/s]100%|██████████| 50/50 [00:04<00:00, 12.23it/s]
Load LoRA latency: 2.91
End2End inference latency: 7.17
==============================
9 papercut -subject/scene-a white robot passing a soccer ball to a red robot, 4k, clean background
[SUYI] load_file_time=0.463
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.921
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 3.13
[SUYI] load_lora_into_unet_time=3.140
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.22it/s]  8%|▊         | 4/50 [00:00<00:03, 12.93it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.55it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.30it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.24it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.21it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.18it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.17it/s] 40%|████      | 20/50 [00:01<00:02, 12.16it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.15it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.15it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.14it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.14it/s] 60%|██████    | 30/50 [00:02<00:01, 12.14it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.13it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.13it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.13it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.13it/s] 80%|████████  | 40/50 [00:03<00:00, 12.13it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.13it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.13it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.13it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.13it/s]100%|██████████| 50/50 [00:04<00:00, 12.13it/s]100%|██████████| 50/50 [00:04<00:00, 12.20it/s]
Load LoRA latency: 3.70
End2End inference latency: 7.96
==============================
10 papercut -subject/scene-a plant growing on the side of a brick wall, 4k, clean background
[SUYI] load_file_time=0.496
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.176
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.41
[SUYI] load_lora_into_unet_time=2.416
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.23it/s]  8%|▊         | 4/50 [00:00<00:03, 12.92it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.55it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.30it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.26it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.19it/s] 40%|████      | 20/50 [00:01<00:02, 12.18it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.18it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.17it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.17it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.17it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.17it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.16it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.16it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.16it/s] 80%|████████  | 40/50 [00:03<00:00, 12.17it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.17it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.16it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.16it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.23it/s]
Load LoRA latency: 3.01
End2End inference latency: 7.26
==============================
11 papercut -subject/scene-snow covering the Great Pyramid, 4k, clean background
[SUYI] load_file_time=0.462
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.051
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.26
[SUYI] load_lora_into_unet_time=2.269
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.21it/s]  8%|▊         | 4/50 [00:00<00:03, 12.92it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.56it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.40it/s] 20%|██        | 10/50 [00:00<00:03, 12.32it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.27it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.24it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.21it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.20it/s] 40%|████      | 20/50 [00:01<00:02, 12.19it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.18it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.17it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.17it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.16it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.16it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.17it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.17it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.17it/s] 80%|████████  | 40/50 [00:03<00:00, 12.16it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.17it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.17it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.17it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.23it/s]
Load LoRA latency: 2.83
End2End inference latency: 7.08
==============================
12 papercut -subject/scene-a photograph of a house on a mountain, 4k, clean background
[SUYI] load_file_time=0.467
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.154
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.36
[SUYI] load_lora_into_unet_time=2.374
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.23it/s]  8%|▊         | 4/50 [00:00<00:03, 12.93it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.57it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.40it/s] 20%|██        | 10/50 [00:00<00:03, 12.31it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.26it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.23it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.21it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.20it/s] 40%|████      | 20/50 [00:01<00:02, 12.19it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.18it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.18it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.17it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.17it/s] 60%|██████    | 30/50 [00:02<00:01, 12.16it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.17it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.17it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.17it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.16it/s] 80%|████████  | 40/50 [00:03<00:00, 12.16it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.16it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.17it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.17it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.23it/s]
Load LoRA latency: 2.94
End2End inference latency: 7.20
==============================
13 papercut -subject/scene-an owl standing on a wire, 4k, clean background
[SUYI] load_file_time=0.471
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.087
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.30
[SUYI] load_lora_into_unet_time=2.309
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.23it/s]  8%|▊         | 4/50 [00:00<00:03, 12.93it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.56it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.30it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.25it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.23it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.21it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.20it/s] 40%|████      | 20/50 [00:01<00:02, 12.19it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.19it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.18it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.18it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.18it/s] 60%|██████    | 30/50 [00:02<00:01, 12.18it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.18it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.18it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.18it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.18it/s] 80%|████████  | 40/50 [00:03<00:00, 12.17it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.17it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.17it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.17it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.17it/s]100%|██████████| 50/50 [00:04<00:00, 12.17it/s]100%|██████████| 50/50 [00:04<00:00, 12.24it/s]
Load LoRA latency: 2.88
End2End inference latency: 7.13
==============================
14 papercut -subject/scene-a kids' book cover with an illustration of white dog driving a red pickup truck, 4k, clean background
[SUYI] load_file_time=0.622
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.235
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.45
[SUYI] load_lora_into_unet_time=2.460
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.22it/s]  8%|▊         | 4/50 [00:00<00:03, 12.91it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.54it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.38it/s] 20%|██        | 10/50 [00:00<00:03, 12.30it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.26it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.23it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.21it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.20it/s] 40%|████      | 20/50 [00:01<00:02, 12.19it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.17it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.17it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.17it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.17it/s] 60%|██████    | 30/50 [00:02<00:01, 12.16it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.16it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.16it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.15it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.15it/s] 80%|████████  | 40/50 [00:03<00:00, 12.15it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.15it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.15it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.15it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.22it/s]
Load LoRA latency: 3.18
End2End inference latency: 7.44
==============================
15 papercut -subject/scene-a subway train coming out of a tunnel, 4k, clean background
[SUYI] load_file_time=0.464
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.134
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.35
[SUYI] load_lora_into_unet_time=2.356
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.24it/s]  8%|▊         | 4/50 [00:00<00:03, 12.93it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.55it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.31it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.26it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.23it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.19it/s] 40%|████      | 20/50 [00:01<00:02, 12.18it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.17it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.16it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.16it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.16it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.16it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.16it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.16it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.16it/s] 80%|████████  | 40/50 [00:03<00:00, 12.16it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.16it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.15it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.15it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.23it/s]
Load LoRA latency: 2.92
End2End inference latency: 7.17
==============================
16 papercut -subject/scene-a stone path leading away from a fountain, 4k, clean background
[SUYI] load_file_time=0.486
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.675
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.89
[SUYI] load_lora_into_unet_time=2.896
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.22it/s]  8%|▊         | 4/50 [00:00<00:03, 12.91it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.54it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.38it/s] 20%|██        | 10/50 [00:00<00:03, 12.29it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.25it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.21it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.19it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.18it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.17it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.16it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.16it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.16it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.15it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.15it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.15it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.15it/s] 80%|████████  | 40/50 [00:03<00:00, 12.15it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.14it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.14it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.14it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.22it/s]
Load LoRA latency: 3.48
End2End inference latency: 7.74
==============================
17 papercut -subject/scene-an antique car by a beach, 4k, clean background
[SUYI] load_file_time=0.468
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.061
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.27
[SUYI] load_lora_into_unet_time=2.277
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.23it/s]  8%|▊         | 4/50 [00:00<00:03, 12.93it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.56it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.40it/s] 20%|██        | 10/50 [00:00<00:03, 12.31it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.26it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.19it/s] 40%|████      | 20/50 [00:01<00:02, 12.18it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.18it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.18it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.17it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.17it/s] 60%|██████    | 30/50 [00:02<00:01, 12.16it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.16it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.16it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.16it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.16it/s] 80%|████████  | 40/50 [00:03<00:00, 12.16it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.16it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.16it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.16it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.23it/s]
Load LoRA latency: 2.84
End2End inference latency: 7.10
==============================
18 papercut -subject/scene-black hi-top sneakers with the Nike swoosh, 4k, clean background
[SUYI] load_file_time=0.481
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.121
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.35
[SUYI] load_lora_into_unet_time=2.360
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.24it/s]  8%|▊         | 4/50 [00:00<00:03, 12.94it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.56it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.31it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.25it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.19it/s] 40%|████      | 20/50 [00:01<00:02, 12.18it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.17it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.16it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.16it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.15it/s] 60%|██████    | 30/50 [00:02<00:01, 12.15it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.15it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.15it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.15it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.15it/s] 80%|████████  | 40/50 [00:03<00:00, 12.16it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.16it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.16it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.16it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.23it/s]
Load LoRA latency: 2.94
End2End inference latency: 7.19
==============================
19 papercut -subject/scene-a witch riding a broom, 4k, clean background
[SUYI] load_file_time=0.481
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.066
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.27
[SUYI] load_lora_into_unet_time=2.283
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.22it/s]  8%|▊         | 4/50 [00:00<00:03, 12.91it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.55it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.30it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.25it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.21it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.19it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.17it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.16it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.16it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.16it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.16it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.15it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.15it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.15it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.15it/s] 80%|████████  | 40/50 [00:03<00:00, 12.15it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.15it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.14it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.15it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.22it/s]
Load LoRA latency: 2.86
End2End inference latency: 7.12
==============================
20 papercut -subject/scene-a sword in a stone, 4k, clean background
[SUYI] load_file_time=0.454
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.064
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.27
[SUYI] load_lora_into_unet_time=2.283
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.25it/s]  8%|▊         | 4/50 [00:00<00:03, 12.94it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.57it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.40it/s] 20%|██        | 10/50 [00:00<00:03, 12.31it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.25it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.17it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.16it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.16it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.16it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.15it/s] 60%|██████    | 30/50 [00:02<00:01, 12.15it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.15it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.15it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.14it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.14it/s] 80%|████████  | 40/50 [00:03<00:00, 12.14it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.14it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.14it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.14it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.22it/s]
Load LoRA latency: 2.83
End2End inference latency: 7.09
==============================
21 papercut -subject/scene-cash on a wooden table, 4k, clean background
[SUYI] load_file_time=0.468
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.165
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.37
[SUYI] load_lora_into_unet_time=2.384
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.20it/s]  8%|▊         | 4/50 [00:00<00:03, 12.91it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.55it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.38it/s] 20%|██        | 10/50 [00:00<00:03, 12.29it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.25it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.17it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.17it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.17it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.16it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.16it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.16it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.16it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.16it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.15it/s] 80%|████████  | 40/50 [00:03<00:00, 12.15it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.15it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.15it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.15it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.22it/s]
Load LoRA latency: 2.95
End2End inference latency: 7.21
==============================
22 papercut -subject/scene-the Millennium Wheel in a snow storm, 4k, clean background
[SUYI] load_file_time=0.466
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.104
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.31
[SUYI] load_lora_into_unet_time=2.321
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.24it/s]  8%|▊         | 4/50 [00:00<00:03, 12.93it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.55it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.30it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.25it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.18it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.18it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.17it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.17it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.16it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.16it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.17it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.17it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.17it/s] 80%|████████  | 40/50 [00:03<00:00, 12.16it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.16it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.16it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.16it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.23it/s]
Load LoRA latency: 2.88
End2End inference latency: 7.14
==============================
23 papercut -subject/scene-a knight holding a long sword, 4k, clean background
[SUYI] load_file_time=0.506
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.057
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.26
[SUYI] load_lora_into_unet_time=2.273
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.23it/s]  8%|▊         | 4/50 [00:00<00:03, 12.92it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.55it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.38it/s] 20%|██        | 10/50 [00:00<00:03, 12.30it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.26it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.23it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.21it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.20it/s] 40%|████      | 20/50 [00:01<00:02, 12.18it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.17it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.16it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.16it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.17it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.16it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.16it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.16it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.16it/s] 80%|████████  | 40/50 [00:03<00:00, 12.16it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.16it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.15it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.15it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.23it/s]
Load LoRA latency: 2.87
End2End inference latency: 7.13
==============================
24 papercut -subject/scene-a smiling sloth, 4k, clean background
[SUYI] load_file_time=0.466
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.040
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.25
[SUYI] load_lora_into_unet_time=2.257
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.24it/s]  8%|▊         | 4/50 [00:00<00:03, 12.93it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.55it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.31it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.26it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.23it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.17it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.17it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.17it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.16it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.16it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.16it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.16it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.16it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.16it/s] 80%|████████  | 40/50 [00:03<00:00, 12.16it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.17it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.16it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.15it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.15it/s]100%|██████████| 50/50 [00:04<00:00, 12.23it/s]
Load LoRA latency: 2.82
End2End inference latency: 7.08
==============================
25 papercut -subject/scene-a bundle of blue and yellow flowers in a vase, 4k, clean background
[SUYI] load_file_time=0.478
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.112
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.32
[SUYI] load_lora_into_unet_time=2.333
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.23it/s]  8%|▊         | 4/50 [00:00<00:03, 12.91it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.55it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.30it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.25it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.17it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.16it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.16it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.16it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.16it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.16it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.16it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.16it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.16it/s] 80%|████████  | 40/50 [00:03<00:00, 12.16it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.16it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.16it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.16it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.22it/s]
Load LoRA latency: 2.91
End2End inference latency: 7.17
==============================
26 papercut -subject/scene-a cat coming through a cat door, 4k, clean background
[SUYI] load_file_time=0.469
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.069
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.30
[SUYI] load_lora_into_unet_time=2.313
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.25it/s]  8%|▊         | 4/50 [00:00<00:03, 12.93it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.55it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.38it/s] 20%|██        | 10/50 [00:00<00:03, 12.29it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.24it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.21it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.18it/s] 40%|████      | 20/50 [00:01<00:02, 12.17it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.17it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.17it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.17it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.17it/s] 60%|██████    | 30/50 [00:02<00:01, 12.17it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.17it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.17it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.17it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.16it/s] 80%|████████  | 40/50 [00:03<00:00, 12.17it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.17it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.16it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.16it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.23it/s]
Load LoRA latency: 2.88
End2End inference latency: 7.14
==============================
27 papercut -subject/scene-a pickup truck going up a mountain switchback, 4k, clean background
[SUYI] load_file_time=0.458
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.165
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.37
[SUYI] load_lora_into_unet_time=2.383
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.22it/s]  8%|▊         | 4/50 [00:00<00:03, 12.90it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.53it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.37it/s] 20%|██        | 10/50 [00:00<00:03, 12.28it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.22it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.19it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.17it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.16it/s] 40%|████      | 20/50 [00:01<00:02, 12.15it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.15it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.15it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.15it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.14it/s] 60%|██████    | 30/50 [00:02<00:01, 12.14it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.15it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.15it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.15it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.14it/s] 80%|████████  | 40/50 [00:03<00:00, 12.14it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.14it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.14it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.14it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.21it/s]
Load LoRA latency: 2.94
End2End inference latency: 7.20
==============================
28 papercut -subject/scene-a street in Paris, 4k, clean background
[SUYI] load_file_time=0.476
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.059
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.27
[SUYI] load_lora_into_unet_time=2.277
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.23it/s]  8%|▊         | 4/50 [00:00<00:04,  9.22it/s] 12%|█▏        | 6/50 [00:00<00:04, 10.36it/s] 16%|█▌        | 8/50 [00:00<00:03, 10.99it/s] 20%|██        | 10/50 [00:00<00:03, 11.37it/s] 24%|██▍       | 12/50 [00:01<00:03, 11.62it/s] 28%|██▊       | 14/50 [00:01<00:03, 11.78it/s] 32%|███▏      | 16/50 [00:01<00:02, 11.89it/s] 36%|███▌      | 18/50 [00:01<00:02, 11.96it/s] 40%|████      | 20/50 [00:01<00:02, 12.01it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.05it/s] 48%|████▊     | 24/50 [00:02<00:02, 12.09it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.11it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.12it/s] 60%|██████    | 30/50 [00:02<00:01, 12.13it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.13it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.14it/s] 72%|███████▏  | 36/50 [00:03<00:01, 12.14it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.14it/s] 80%|████████  | 40/50 [00:03<00:00, 12.15it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.15it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.15it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.16it/s] 96%|█████████▌| 48/50 [00:04<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 12.16it/s]100%|██████████| 50/50 [00:04<00:00, 11.90it/s]
Load LoRA latency: 2.85
End2End inference latency: 7.21
==============================
29 papercut -subject/scene-a teddy bear on a skateboard, 4k, clean background
[SUYI] load_file_time=0.463
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.045
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.25
[SUYI] load_lora_into_unet_time=2.262
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/50 [00:00<?, ?it/s]  4%|▍         | 2/50 [00:00<00:03, 14.23it/s]  8%|▊         | 4/50 [00:00<00:03, 12.93it/s] 12%|█▏        | 6/50 [00:00<00:03, 12.56it/s] 16%|█▌        | 8/50 [00:00<00:03, 12.39it/s] 20%|██        | 10/50 [00:00<00:03, 12.30it/s] 24%|██▍       | 12/50 [00:00<00:03, 12.25it/s] 28%|██▊       | 14/50 [00:01<00:02, 12.22it/s] 32%|███▏      | 16/50 [00:01<00:02, 12.20it/s] 36%|███▌      | 18/50 [00:01<00:02, 12.19it/s] 40%|████      | 20/50 [00:01<00:02, 12.18it/s] 44%|████▍     | 22/50 [00:01<00:02, 12.17it/s] 48%|████▊     | 24/50 [00:01<00:02, 12.17it/s] 52%|█████▏    | 26/50 [00:02<00:01, 12.17it/s] 56%|█████▌    | 28/50 [00:02<00:01, 12.16it/s] 60%|██████    | 30/50 [00:02<00:01, 12.15it/s] 64%|██████▍   | 32/50 [00:02<00:01, 12.15it/s] 68%|██████▊   | 34/50 [00:02<00:01, 12.15it/s] 72%|███████▏  | 36/50 [00:02<00:01, 12.15it/s] 76%|███████▌  | 38/50 [00:03<00:00, 12.15it/s] 80%|████████  | 40/50 [00:03<00:00, 12.15it/s] 84%|████████▍ | 42/50 [00:03<00:00, 12.14it/s] 88%|████████▊ | 44/50 [00:03<00:00, 12.14it/s] 92%|█████████▏| 46/50 [00:03<00:00, 12.14it/s] 96%|█████████▌| 48/50 [00:03<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.14it/s]100%|██████████| 50/50 [00:04<00:00, 12.22it/s]
Load LoRA latency: 2.82
End2End inference latency: 7.08
==============================
