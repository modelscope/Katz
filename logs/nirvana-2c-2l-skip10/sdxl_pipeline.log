[SUYI] Using EulerDiscreteScheduler
[SUYI] In unet_2d_condition.py
[SUYI] USE_PEFT_BACKEND=True in loaders/lora.py
Args Namespace(skipped_steps=10, enable_hit_ratio=False, serve_mode='standard', lora_mode='full', load_lora_mode='default', num_controlnets=2, num_loras=2)
Nirvana config {'K': 10, 'hit_ratio': 0.66}
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] load_state_dict: safetensors.torch.load_file(/home/slida/.cache/huggingface/hub/models--diffusers--controlnet-depth-sdxl-1.0/snapshots/17bb97973f29801224cd66f192c5ffacf82648b4/diffusion_pytorch_model.fp16.safetensors)
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] load_state_dict: safetensors.torch.load_file(/home/slida/.cache/huggingface/hub/models--diffusers--controlnet-depth-sdxl-1.0/snapshots/17bb97973f29801224cd66f192c5ffacf82648b4/diffusion_pytorch_model.fp16.safetensors)
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] load_state_dict: safetensors.torch.load_file(/home/slida/.cache/huggingface/hub/models--madebyollin--sdxl-vae-fp16-fix/snapshots/207b116dae70ace3637169f1ddd2434b91b3a8cd/diffusion_pytorch_model.safetensors)
[SUYI] Using customized pipeline_stable_diffusion_xl
Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]Loading pipeline components...:  14%|█▍        | 1/7 [00:00<00:01,  4.13it/s]Loading pipeline components...:  43%|████▎     | 3/7 [00:00<00:00,  9.94it/s]Loading pipeline components...:  71%|███████▏  | 5/7 [00:13<00:06,  3.47s/it]Loading pipeline components...: 100%|██████████| 7/7 [00:13<00:00,  1.96s/it]
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_geglu: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_channels_last: False
[LINGYUN] norm_num_groups: 32
[LINGYUN] enable_fused_norm_silu:  False
[LINGYUN] enable_cuda_graph: False
[LINGYUN] load_state_dict: safetensors.torch.load_file(/home/slida/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-base-1.0/snapshots/462165984030d82259a11f4367a4eed129e94a7b/unet/diffusion_pytorch_model.fp16.safetensors)
0 by william eggleston, a long wooden bench in front of a brick wall, 4k, clean background
[SUYI] load_file_time=0.487
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.119
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.27
[SUYI] load_lora_into_unet_time=2.280
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.140
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.529
[SUYI] load_file_time=0.534
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.810
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 3.00
[SUYI] load_lora_into_unet_time=3.005
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  2%|▎         | 1/40 [00:00<00:09,  4.09it/s]  8%|▊         | 3/40 [00:00<00:05,  7.36it/s] 10%|█         | 4/40 [00:00<00:04,  7.88it/s] 12%|█▎        | 5/40 [00:00<00:04,  8.24it/s] 15%|█▌        | 6/40 [00:00<00:04,  8.50it/s] 18%|█▊        | 7/40 [00:00<00:03,  8.67it/s] 20%|██        | 8/40 [00:00<00:03,  8.80it/s] 22%|██▎       | 9/40 [00:01<00:03,  8.90it/s] 25%|██▌       | 10/40 [00:01<00:03,  8.96it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.01it/s] 30%|███       | 12/40 [00:01<00:03,  9.03it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.05it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.07it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.08it/s] 40%|████      | 16/40 [00:01<00:02,  9.09it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:02<00:02,  9.11it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.11it/s] 50%|█████     | 20/40 [00:02<00:02,  9.11it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.11it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.12it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.12it/s] 60%|██████    | 24/40 [00:02<00:01,  9.12it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.12it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.12it/s] 68%|██████▊   | 27/40 [00:03<00:01,  9.12it/s] 70%|███████   | 28/40 [00:03<00:01,  9.12it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.12it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.12it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.12it/s] 80%|████████  | 32/40 [00:03<00:00,  9.12it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.12it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.12it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:04<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.12it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.12it/s]100%|██████████| 40/40 [00:04<00:00,  8.89it/s]
Load LoRA latency: 7.57
End2End inference latency: 12.61
==============================
1 by william eggleston, a cat looking out of a window, 4k, clean background
[SUYI] load_file_time=0.588
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.936
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.09
[SUYI] load_lora_into_unet_time=2.103
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.123
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.475
[SUYI] load_file_time=0.514
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.418
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.61
[SUYI] load_lora_into_unet_time=2.619
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.19it/s] 10%|█         | 4/40 [00:00<00:03,  9.50it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.36it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.28it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.23it/s] 20%|██        | 8/40 [00:00<00:03,  9.19it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.16it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.14it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.13it/s] 30%|███       | 12/40 [00:01<00:03,  9.12it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.11it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.11it/s] 40%|████      | 16/40 [00:01<00:02,  9.10it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.11it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.10it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.10it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.14it/s]
Load LoRA latency: 6.70
End2End inference latency: 11.33
==============================
2 by william eggleston, A helicopter flies over Yosemite., 4k, clean background
[SUYI] load_file_time=0.579
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.913
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.06
[SUYI] load_lora_into_unet_time=2.078
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.118
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.459
[SUYI] load_file_time=0.487
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.411
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.60
[SUYI] load_lora_into_unet_time=2.614
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.24it/s] 10%|█         | 4/40 [00:00<00:03,  9.53it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.40it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.31it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.25it/s] 20%|██        | 8/40 [00:00<00:03,  9.21it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.18it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.15it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.07it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.14it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.13it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.13it/s] 50%|█████     | 20/40 [00:02<00:02,  9.12it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.12it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.12it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.12it/s] 60%|██████    | 24/40 [00:02<00:01,  9.12it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.12it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.12it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.12it/s] 70%|███████   | 28/40 [00:03<00:01,  9.11it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.11it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.11it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.11it/s] 80%|████████  | 32/40 [00:03<00:00,  9.11it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.62
End2End inference latency: 11.24
==============================
3 by william eggleston, a handsaw on a table, 4k, clean background
[SUYI] load_file_time=0.519
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.901
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.16
[SUYI] load_lora_into_unet_time=2.171
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.118
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.459
[SUYI] load_file_time=0.503
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.402
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.59
[SUYI] load_lora_into_unet_time=2.603
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.21it/s] 10%|█         | 4/40 [00:00<00:03,  9.52it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.39it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.30it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.23it/s] 20%|██        | 8/40 [00:00<00:03,  9.19it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.16it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.14it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.13it/s] 30%|███       | 12/40 [00:01<00:03,  9.12it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.11it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.10it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.10it/s] 40%|████      | 16/40 [00:01<00:02,  9.10it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.10it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.10it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.06it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.11it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.11it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.11it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.66
End2End inference latency: 11.29
==============================
4 by william eggleston, A smiling sloth wearing a bowtie and holding a quarterstaff and a big book. A shiny VW van parked on grass., 4k, clean background
[SUYI] load_file_time=0.502
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.908
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.06
[SUYI] load_lora_into_unet_time=2.073
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.117
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.570
[SUYI] load_file_time=0.489
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.412
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.60
[SUYI] load_lora_into_unet_time=2.611
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.22it/s] 10%|█         | 4/40 [00:00<00:03,  9.53it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.40it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.32it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.26it/s] 20%|██        | 8/40 [00:00<00:03,  9.22it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.19it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.15it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.06it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.14it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.13it/s] 50%|█████     | 20/40 [00:02<00:02,  9.13it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.12it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.12it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.12it/s] 60%|██████    | 24/40 [00:02<00:01,  9.03it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.14it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.14it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.13it/s] 70%|███████   | 28/40 [00:03<00:01,  9.13it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.12it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.12it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.12it/s] 80%|████████  | 32/40 [00:03<00:00,  9.12it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.11it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.11it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.64
End2End inference latency: 11.27
==============================
5 by william eggleston, a large present with a red ribbon, 4k, clean background
[SUYI] load_file_time=0.490
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.919
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.07
[SUYI] load_lora_into_unet_time=2.087
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.118
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.469
[SUYI] load_file_time=0.465
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.531
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.72
[SUYI] load_lora_into_unet_time=2.730
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.22it/s] 10%|█         | 4/40 [00:00<00:03,  9.53it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.40it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.31it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.25it/s] 20%|██        | 8/40 [00:00<00:03,  9.20it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.17it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.14it/s] 30%|███       | 12/40 [00:01<00:03,  9.13it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.12it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.11it/s] 40%|████      | 16/40 [00:01<00:02,  9.10it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.10it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.10it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.06it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.11it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.63
End2End inference latency: 11.26
==============================
6 by william eggleston, a cat reading a book, 4k, clean background
[SUYI] load_file_time=0.495
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.901
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.06
[SUYI] load_lora_into_unet_time=2.069
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.130
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.458
[SUYI] load_file_time=0.479
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.387
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.58
[SUYI] load_lora_into_unet_time=2.589
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.22it/s] 10%|█         | 4/40 [00:00<00:03,  9.53it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.40it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.31it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.25it/s] 20%|██        | 8/40 [00:00<00:03,  9.21it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.18it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.15it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.12it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.12it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.12it/s] 50%|█████     | 20/40 [00:02<00:02,  9.11it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.11it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.11it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.11it/s] 60%|██████    | 24/40 [00:02<00:01,  9.11it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.11it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.12it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.12it/s] 70%|███████   | 28/40 [00:03<00:01,  9.12it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.11it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.11it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.11it/s] 80%|████████  | 32/40 [00:03<00:00,  9.11it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.11it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.11it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.50
End2End inference latency: 11.13
==============================
7 by william eggleston, the Beatles crossing Abbey road, 4k, clean background
[SUYI] load_file_time=0.490
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.918
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.18
[SUYI] load_lora_into_unet_time=2.190
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.121
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.453
[SUYI] load_file_time=0.475
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.375
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.57
[SUYI] load_lora_into_unet_time=2.577
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.20it/s] 10%|█         | 4/40 [00:00<00:03,  9.50it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.38it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.29it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.24it/s] 20%|██        | 8/40 [00:00<00:03,  9.19it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.16it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.13it/s] 30%|███       | 12/40 [00:01<00:03,  9.06it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.14it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.11it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.11it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.11it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.11it/s] 50%|█████     | 20/40 [00:02<00:02,  9.11it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.06it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.11it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.11it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.58
End2End inference latency: 11.21
==============================
8 by william eggleston, a woman singing into a microphone, 4k, clean background
[SUYI] load_file_time=0.564
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.914
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.07
[SUYI] load_lora_into_unet_time=2.082
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.121
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.569
[SUYI] load_file_time=0.473
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.390
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.58
[SUYI] load_lora_into_unet_time=2.590
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.23it/s] 10%|█         | 4/40 [00:00<00:03,  9.54it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.41it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.32it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.26it/s] 20%|██        | 8/40 [00:00<00:03,  9.21it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.19it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.17it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.15it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.12it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.12it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.11it/s] 50%|█████     | 20/40 [00:02<00:02,  9.12it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.11it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.06it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.14it/s] 60%|██████    | 24/40 [00:02<00:01,  9.13it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.13it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.13it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.12it/s] 70%|███████   | 28/40 [00:03<00:01,  9.12it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.12it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.12it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.11it/s] 80%|████████  | 32/40 [00:03<00:00,  9.11it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.11it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.11it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.68
End2End inference latency: 11.30
==============================
9 by william eggleston, a white robot passing a soccer ball to a red robot, 4k, clean background
[SUYI] load_file_time=0.492
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.930
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.08
[SUYI] load_lora_into_unet_time=2.098
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.127
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.473
[SUYI] load_file_time=0.483
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.522
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.71
[SUYI] load_lora_into_unet_time=2.723
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.21it/s] 10%|█         | 4/40 [00:00<00:03,  9.51it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.38it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.29it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.23it/s] 20%|██        | 8/40 [00:00<00:03,  9.19it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.16it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.13it/s] 30%|███       | 12/40 [00:01<00:03,  9.12it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.11it/s] 35%|███▌      | 14/40 [00:01<00:02,  8.92it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.18it/s] 40%|████      | 16/40 [00:01<00:02,  9.15it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.14it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.13it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.12it/s] 50%|█████     | 20/40 [00:02<00:02,  9.12it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.11it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.11it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.06it/s] 60%|██████    | 24/40 [00:02<00:01,  9.12it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.11it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.11it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.11it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.67
End2End inference latency: 11.30
==============================
10 by william eggleston, a plant growing on the side of a brick wall, 4k, clean background
[SUYI] load_file_time=0.486
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.922
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.07
[SUYI] load_lora_into_unet_time=2.088
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.122
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.457
[SUYI] load_file_time=0.617
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.394
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.59
[SUYI] load_lora_into_unet_time=2.596
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.23it/s] 10%|█         | 4/40 [00:00<00:03,  9.53it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.40it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.31it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.25it/s] 20%|██        | 8/40 [00:00<00:03,  9.21it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.18it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.15it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.13it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.12it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.11it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.12it/s] 50%|█████     | 20/40 [00:02<00:02,  9.12it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.12it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.12it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.12it/s] 60%|██████    | 24/40 [00:02<00:01,  9.12it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.12it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.12it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.12it/s] 70%|███████   | 28/40 [00:03<00:01,  9.12it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.11it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.12it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.12it/s] 80%|████████  | 32/40 [00:03<00:00,  9.12it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.12it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.12it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.12it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.12it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.12it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.12it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.64
End2End inference latency: 11.26
==============================
11 by william eggleston, snow covering the Great Pyramid, 4k, clean background
[SUYI] load_file_time=0.521
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.717
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 1.87
[SUYI] load_lora_into_unet_time=1.882
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.219
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.416
[SUYI] load_file_time=0.474
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.159
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.35
[SUYI] load_lora_into_unet_time=2.357
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.25it/s] 10%|█         | 4/40 [00:00<00:03,  9.54it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.41it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.31it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.25it/s] 20%|██        | 8/40 [00:00<00:03,  9.20it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.17it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.13it/s] 30%|███       | 12/40 [00:01<00:03,  9.12it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.12it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.11it/s] 40%|████      | 16/40 [00:01<00:02,  9.10it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.10it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.10it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.14
End2End inference latency: 10.77
==============================
12 by william eggleston, a photograph of a house on a mountain, 4k, clean background
[SUYI] load_file_time=0.521
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.750
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 1.90
[SUYI] load_lora_into_unet_time=1.916
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.106
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.513
[SUYI] load_file_time=0.470
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.143
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.33
[SUYI] load_lora_into_unet_time=2.342
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.24it/s] 10%|█         | 4/40 [00:00<00:03,  9.55it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.41it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.32it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.26it/s] 20%|██        | 8/40 [00:00<00:03,  9.21it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.18it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.14it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.12it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.12it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.12it/s] 50%|█████     | 20/40 [00:02<00:02,  9.12it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.11it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.11it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.11it/s] 60%|██████    | 24/40 [00:02<00:01,  9.11it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.11it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.11it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.11it/s] 70%|███████   | 28/40 [00:03<00:01,  9.11it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.11it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.11it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.11it/s] 80%|████████  | 32/40 [00:03<00:00,  9.11it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.11it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.11it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.14
End2End inference latency: 10.76
==============================
13 by william eggleston, an owl standing on a wire, 4k, clean background
[SUYI] load_file_time=0.492
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.770
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 1.92
[SUYI] load_lora_into_unet_time=1.935
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.110
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.409
[SUYI] load_file_time=0.483
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.248
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.44
[SUYI] load_lora_into_unet_time=2.447
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.22it/s] 10%|█         | 4/40 [00:00<00:03,  9.53it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.40it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.31it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.24it/s] 20%|██        | 8/40 [00:00<00:03,  9.20it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.17it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.13it/s] 30%|███       | 12/40 [00:01<00:03,  9.12it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.11it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.11it/s] 40%|████      | 16/40 [00:01<00:02,  9.10it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.10it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.10it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.09it/s] 80%|████████  | 32/40 [00:03<00:00,  9.09it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.09it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.09it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.09it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.09it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.15
End2End inference latency: 10.78
==============================
14 by william eggleston, a kids' book cover with an illustration of white dog driving a red pickup truck, 4k, clean background
[SUYI] load_file_time=0.581
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.875
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.17
[SUYI] load_lora_into_unet_time=2.182
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.122
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.481
[SUYI] load_file_time=0.474
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.393
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.58
[SUYI] load_lora_into_unet_time=2.588
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.25it/s] 10%|█         | 4/40 [00:00<00:03,  9.55it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.42it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.33it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.26it/s] 20%|██        | 8/40 [00:00<00:03,  9.18it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.20it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.17it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.16it/s] 30%|███       | 12/40 [00:01<00:03,  9.15it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.14it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  8.93it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.19it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.17it/s] 50%|█████     | 20/40 [00:02<00:02,  9.15it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.14it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.13it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.12it/s] 60%|██████    | 24/40 [00:02<00:01,  9.12it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.12it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.12it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.12it/s] 70%|███████   | 28/40 [00:03<00:01,  9.11it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.11it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.11it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.11it/s] 80%|████████  | 32/40 [00:03<00:00,  9.11it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.11it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.11it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.71
End2End inference latency: 11.34
==============================
15 by william eggleston, a subway train coming out of a tunnel, 4k, clean background
[SUYI] load_file_time=0.498
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.899
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.062
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.118
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.567
[SUYI] load_file_time=0.482
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.377
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.56
[SUYI] load_lora_into_unet_time=2.570
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.22it/s] 10%|█         | 4/40 [00:00<00:03,  9.53it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.40it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.31it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.24it/s] 20%|██        | 8/40 [00:00<00:03,  9.20it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.17it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.14it/s] 30%|███       | 12/40 [00:01<00:03,  9.13it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.12it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.11it/s] 40%|████      | 16/40 [00:01<00:02,  9.11it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.11it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.11it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.11it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.57
End2End inference latency: 11.20
==============================
16 by william eggleston, a stone path leading away from a fountain, 4k, clean background
[SUYI] load_file_time=0.489
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.893
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.058
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.116
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.460
[SUYI] load_file_time=0.478
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.535
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.72
[SUYI] load_lora_into_unet_time=2.729
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.24it/s] 10%|█         | 4/40 [00:00<00:03,  9.55it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.40it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.33it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.26it/s] 20%|██        | 8/40 [00:00<00:03,  9.22it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.18it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.15it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.12it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.12it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.12it/s] 50%|█████     | 20/40 [00:02<00:02,  9.12it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.12it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.11it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.11it/s] 60%|██████    | 24/40 [00:02<00:01,  9.11it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.11it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.11it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.11it/s] 70%|███████   | 28/40 [00:03<00:01,  9.11it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.11it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.11it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.11it/s] 80%|████████  | 32/40 [00:03<00:00,  9.11it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.11it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.11it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.61
End2End inference latency: 11.23
==============================
17 by william eggleston, an antique car by a beach, 4k, clean background
[SUYI] load_file_time=0.530
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.929
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.08
[SUYI] load_lora_into_unet_time=2.092
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.123
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.464
[SUYI] load_file_time=0.464
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.384
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.57
[SUYI] load_lora_into_unet_time=2.577
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.23it/s] 10%|█         | 4/40 [00:00<00:03,  9.53it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.40it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.31it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.25it/s] 20%|██        | 8/40 [00:00<00:03,  9.20it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.17it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.13it/s] 30%|███       | 12/40 [00:01<00:03,  9.12it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.12it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.11it/s] 40%|████      | 16/40 [00:01<00:02,  9.10it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.10it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.10it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.53
End2End inference latency: 11.15
==============================
18 by william eggleston, black hi-top sneakers with the Nike swoosh, 4k, clean background
[SUYI] load_file_time=0.499
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.885
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.14
[SUYI] load_lora_into_unet_time=2.152
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.117
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.456
[SUYI] load_file_time=0.471
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.407
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.59
[SUYI] load_lora_into_unet_time=2.602
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.23it/s] 10%|█         | 4/40 [00:00<00:03,  9.54it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.40it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.32it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.25it/s] 20%|██        | 8/40 [00:00<00:03,  9.21it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.18it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.15it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.12it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.12it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.12it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.12it/s] 50%|█████     | 20/40 [00:02<00:02,  9.12it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.12it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.12it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.11it/s] 60%|██████    | 24/40 [00:02<00:01,  9.11it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.12it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.12it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.12it/s] 70%|███████   | 28/40 [00:03<00:01,  9.12it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.12it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.12it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.12it/s] 80%|████████  | 32/40 [00:03<00:00,  9.12it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.12it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.12it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.57
End2End inference latency: 11.20
==============================
19 by william eggleston, a witch riding a broom, 4k, clean background
[SUYI] load_file_time=0.496
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.910
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.06
[SUYI] load_lora_into_unet_time=2.077
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.118
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.569
[SUYI] load_file_time=0.480
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.388
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.57
[SUYI] load_lora_into_unet_time=2.583
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.22it/s] 10%|█         | 4/40 [00:00<00:03,  9.52it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.39it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.31it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.24it/s] 20%|██        | 8/40 [00:00<00:03,  9.20it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.17it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.14it/s] 30%|███       | 12/40 [00:01<00:03,  9.13it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.12it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.11it/s] 40%|████      | 16/40 [00:01<00:02,  9.11it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.10it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.10it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.60
End2End inference latency: 11.23
==============================
20 by william eggleston, a sword in a stone, 4k, clean background
[SUYI] load_file_time=0.489
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.914
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.07
[SUYI] load_lora_into_unet_time=2.079
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.118
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.460
[SUYI] load_file_time=0.475
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.518
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.71
[SUYI] load_lora_into_unet_time=2.714
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.24it/s] 10%|█         | 4/40 [00:00<00:03,  9.54it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.41it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.32it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.26it/s] 20%|██        | 8/40 [00:00<00:03,  9.22it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.19it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.15it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.12it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.12it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.12it/s] 50%|█████     | 20/40 [00:02<00:02,  9.12it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.11it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.11it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.11it/s] 60%|██████    | 24/40 [00:02<00:01,  9.11it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.11it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.11it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.11it/s] 70%|███████   | 28/40 [00:03<00:01,  9.11it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.11it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.11it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.11it/s] 80%|████████  | 32/40 [00:03<00:00,  9.11it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.11it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.11it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.61
End2End inference latency: 11.23
==============================
21 by william eggleston, cash on a wooden table, 4k, clean background
[SUYI] load_file_time=0.481
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.892
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.04
[SUYI] load_lora_into_unet_time=2.057
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.117
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.457
[SUYI] load_file_time=0.474
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.377
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.56
[SUYI] load_lora_into_unet_time=2.569
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.21it/s] 10%|█         | 4/40 [00:00<00:03,  9.53it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.40it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.31it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.24it/s] 20%|██        | 8/40 [00:00<00:03,  9.20it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.17it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.13it/s] 30%|███       | 12/40 [00:01<00:03,  9.12it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.12it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.11it/s] 40%|████      | 16/40 [00:01<00:02,  9.11it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.10it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.10it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.07it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.09it/s] 80%|████████  | 32/40 [00:03<00:00,  9.09it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.09it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.09it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.08it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.08it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.08it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.08it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.08it/s]100%|██████████| 40/40 [00:04<00:00,  9.08it/s]100%|██████████| 40/40 [00:04<00:00,  9.14it/s]
Load LoRA latency: 6.43
End2End inference latency: 11.06
==============================
22 by william eggleston, the Millennium Wheel in a snow storm, 4k, clean background
[SUYI] load_file_time=0.480
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.899
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.062
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.228
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.455
[SUYI] load_file_time=0.606
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.396
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.58
[SUYI] load_lora_into_unet_time=2.591
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.23it/s] 10%|█         | 4/40 [00:00<00:03,  9.54it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.41it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.32it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.26it/s] 20%|██        | 8/40 [00:00<00:03,  9.21it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.18it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.14it/s] 30%|███       | 12/40 [00:01<00:03,  9.13it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.12it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.12it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.11it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.11it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.12it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.12it/s] 50%|█████     | 20/40 [00:02<00:02,  9.11it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.11it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.11it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.11it/s] 60%|██████    | 24/40 [00:02<00:01,  9.11it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.12it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.11it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.11it/s] 70%|███████   | 28/40 [00:03<00:01,  9.11it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.11it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.11it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.11it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.11it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.70
End2End inference latency: 11.33
==============================
23 by william eggleston, a knight holding a long sword, 4k, clean background
[SUYI] load_file_time=0.490
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.874
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.03
[SUYI] load_lora_into_unet_time=2.038
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.118
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.566
[SUYI] load_file_time=0.488
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.396
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.59
[SUYI] load_lora_into_unet_time=2.599
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.20it/s] 10%|█         | 4/40 [00:00<00:03,  9.52it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.39it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.30it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.24it/s] 20%|██        | 8/40 [00:00<00:03,  9.20it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.17it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.13it/s] 30%|███       | 12/40 [00:01<00:03,  9.12it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.12it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.11it/s] 40%|████      | 16/40 [00:01<00:02,  9.10it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.11it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.11it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.09it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.09it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.58
End2End inference latency: 11.21
==============================
24 by william eggleston, a smiling sloth, 4k, clean background
[SUYI] load_file_time=0.498
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.907
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.06
[SUYI] load_lora_into_unet_time=2.074
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.115
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.454
[SUYI] load_file_time=0.536
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.496
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.69
[SUYI] load_lora_into_unet_time=2.698
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.25it/s] 10%|█         | 4/40 [00:00<00:03,  9.55it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.42it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.33it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.26it/s] 20%|██        | 8/40 [00:00<00:03,  9.22it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.19it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.15it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.12it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.12it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.12it/s] 50%|█████     | 20/40 [00:02<00:02,  9.12it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.11it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.11it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.11it/s] 60%|██████    | 24/40 [00:02<00:01,  9.02it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.15it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.14it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.13it/s] 70%|███████   | 28/40 [00:03<00:01,  9.13it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.13it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.12it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.12it/s] 80%|████████  | 32/40 [00:03<00:00,  9.12it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.12it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.12it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.12it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.17it/s]
Load LoRA latency: 6.66
End2End inference latency: 11.28
==============================
25 by william eggleston, a bundle of blue and yellow flowers in a vase, 4k, clean background
[SUYI] load_file_time=0.503
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.811
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.07
[SUYI] load_lora_into_unet_time=2.082
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.119
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.457
[SUYI] load_file_time=0.474
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.403
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.60
[SUYI] load_lora_into_unet_time=2.606
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.23it/s] 10%|█         | 4/40 [00:00<00:03,  9.52it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.39it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.30it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.24it/s] 20%|██        | 8/40 [00:00<00:03,  9.20it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.17it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.14it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.13it/s] 30%|███       | 12/40 [00:01<00:03,  9.12it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.12it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.11it/s] 40%|████      | 16/40 [00:01<00:02,  9.10it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.10it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.10it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.52
End2End inference latency: 11.15
==============================
26 by william eggleston, a cat coming through a cat door, 4k, clean background
[SUYI] load_file_time=0.493
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.945
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.10
[SUYI] load_lora_into_unet_time=2.113
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.119
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.571
[SUYI] load_file_time=0.538
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.418
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.61
[SUYI] load_lora_into_unet_time=2.620
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.22it/s] 10%|█         | 4/40 [00:00<00:03,  9.54it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.41it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.32it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.26it/s] 20%|██        | 8/40 [00:00<00:03,  9.21it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.18it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.15it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.13it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.12it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.12it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.12it/s] 50%|█████     | 20/40 [00:02<00:02,  9.12it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.12it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.12it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.12it/s] 60%|██████    | 24/40 [00:02<00:01,  9.12it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.12it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.11it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.11it/s] 70%|███████   | 28/40 [00:03<00:01,  9.11it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.11it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.11it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.11it/s] 80%|████████  | 32/40 [00:03<00:00,  9.12it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.12it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.12it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.73
End2End inference latency: 11.36
==============================
27 by william eggleston, a pickup truck going up a mountain switchback, 4k, clean background
[SUYI] load_file_time=0.482
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.894
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.05
[SUYI] load_lora_into_unet_time=2.062
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.118
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.462
[SUYI] load_file_time=0.936
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.524
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.72
[SUYI] load_lora_into_unet_time=2.726
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.21it/s] 10%|█         | 4/40 [00:00<00:03,  9.52it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.39it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.30it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.24it/s] 20%|██        | 8/40 [00:00<00:03,  9.20it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.17it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.13it/s] 30%|███       | 12/40 [00:01<00:03,  9.12it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.11it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.10it/s] 40%|████      | 16/40 [00:01<00:02,  9.10it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.10it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.10it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.09it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.09it/s] 70%|███████   | 28/40 [00:03<00:01,  9.07it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 7.07
End2End inference latency: 11.70
==============================
28 by william eggleston, a street in Paris, 4k, clean background
[SUYI] load_file_time=0.506
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.909
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.06
[SUYI] load_lora_into_unet_time=2.077
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.117
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.463
[SUYI] load_file_time=0.483
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.420
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.61
[SUYI] load_lora_into_unet_time=2.622
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.24it/s] 10%|█         | 4/40 [00:00<00:03,  9.55it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.41it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.32it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.26it/s] 20%|██        | 8/40 [00:00<00:03,  9.22it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.18it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.16it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.15it/s] 30%|███       | 12/40 [00:01<00:03,  9.14it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.13it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.13it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.12it/s] 40%|████      | 16/40 [00:01<00:02,  9.12it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.12it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.11it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.11it/s] 50%|█████     | 20/40 [00:02<00:02,  9.12it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.12it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.11it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.11it/s] 60%|██████    | 24/40 [00:02<00:01,  9.11it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.11it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.11it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.11it/s] 70%|███████   | 28/40 [00:03<00:01,  9.11it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.11it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.11it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.11it/s] 80%|████████  | 32/40 [00:03<00:00,  9.11it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.11it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.11it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.11it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.11it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.11it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.11it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.11it/s]100%|██████████| 40/40 [00:04<00:00,  9.16it/s]
Load LoRA latency: 6.55
End2End inference latency: 11.17
==============================
29 by william eggleston, a teddy bear on a skateboard, 4k, clean background
[SUYI] load_file_time=0.509
Before inject 1680
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 1.915
After inject 3124
[SUYI] inject_adapter_in_model_with_weights time: 2.17
[SUYI] load_lora_into_unet_time=2.188
[SUYI] len(text_encoder_state_dict) 144
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.119
[SUYI] len(text_encoder_2_state_dict) 384
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 0.455
[SUYI] load_file_time=0.497
Before inject 3124
LoraModel not implement _pre_injection_hook() yet
[SUYI] inject_adapter time 2.401
After inject 4568
[SUYI] inject_adapter_in_model_with_weights time: 2.59
[SUYI] load_lora_into_unet_time=2.601
[SUYI] len(text_encoder_state_dict) 0
[SUYI] len(text_encoder_2_state_dict) 0
lora_scale: 1.0, safe_fusing: False, adapter_names: None
  0%|          | 0/40 [00:00<?, ?it/s]  5%|▌         | 2/40 [00:00<00:03, 10.22it/s] 10%|█         | 4/40 [00:00<00:03,  9.53it/s] 12%|█▎        | 5/40 [00:00<00:03,  9.39it/s] 15%|█▌        | 6/40 [00:00<00:03,  9.30it/s] 18%|█▊        | 7/40 [00:00<00:03,  9.24it/s] 20%|██        | 8/40 [00:00<00:03,  9.20it/s] 22%|██▎       | 9/40 [00:00<00:03,  9.17it/s] 25%|██▌       | 10/40 [00:01<00:03,  9.15it/s] 28%|██▊       | 11/40 [00:01<00:03,  9.14it/s] 30%|███       | 12/40 [00:01<00:03,  9.13it/s] 32%|███▎      | 13/40 [00:01<00:02,  9.12it/s] 35%|███▌      | 14/40 [00:01<00:02,  9.11it/s] 38%|███▊      | 15/40 [00:01<00:02,  9.11it/s] 40%|████      | 16/40 [00:01<00:02,  9.11it/s] 42%|████▎     | 17/40 [00:01<00:02,  9.10it/s] 45%|████▌     | 18/40 [00:01<00:02,  9.10it/s] 48%|████▊     | 19/40 [00:02<00:02,  9.10it/s] 50%|█████     | 20/40 [00:02<00:02,  9.10it/s] 52%|█████▎    | 21/40 [00:02<00:02,  9.10it/s] 55%|█████▌    | 22/40 [00:02<00:01,  9.10it/s] 57%|█████▊    | 23/40 [00:02<00:01,  9.10it/s] 60%|██████    | 24/40 [00:02<00:01,  9.10it/s] 62%|██████▎   | 25/40 [00:02<00:01,  9.10it/s] 65%|██████▌   | 26/40 [00:02<00:01,  9.10it/s] 68%|██████▊   | 27/40 [00:02<00:01,  9.10it/s] 70%|███████   | 28/40 [00:03<00:01,  9.10it/s] 72%|███████▎  | 29/40 [00:03<00:01,  9.10it/s] 75%|███████▌  | 30/40 [00:03<00:01,  9.10it/s] 78%|███████▊  | 31/40 [00:03<00:00,  9.10it/s] 80%|████████  | 32/40 [00:03<00:00,  9.10it/s] 82%|████████▎ | 33/40 [00:03<00:00,  9.10it/s] 85%|████████▌ | 34/40 [00:03<00:00,  9.10it/s] 88%|████████▊ | 35/40 [00:03<00:00,  9.10it/s] 90%|█████████ | 36/40 [00:03<00:00,  9.10it/s] 92%|█████████▎| 37/40 [00:04<00:00,  9.10it/s] 95%|█████████▌| 38/40 [00:04<00:00,  9.10it/s] 98%|█████████▊| 39/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.10it/s]100%|██████████| 40/40 [00:04<00:00,  9.15it/s]
Load LoRA latency: 6.65
End2End inference latency: 11.28
==============================
